* AmuseWiki

This is a wiki engine using the Text::Amuse markup (based on and
mostly compatible with Emacs Muse) and a Git backend. It can work as a
read-only site, as a moderated wiki, or as a fully open wiki or even
as a private site. On a single instance you can run as many sites you
want.

For requirement and installation, see INSTALL.txt

The installed modules use the AmuseWikiFarm namespace for legacy
reasons.

** Testing

DO NOT RUN make test IN THE LIVE DIRECTORY. If you want to run the
tests, do it in a dedicated checkout, as the tests leave a lot of
files behind.

** Users

Permissions are global and if the same user can login on different
sites, it will have the same role. If you trust the user on one site,
but not on another, then create another user with a different
username.

We define 5 levels of users.

*** root permissions

The users with root permissions have full access to anything, but most
important, they can create new sites, change settings, add themes,
etc.. The same login works for all the sites. Given that being able to
access the templates means being able to inject code, this role should
be reserved to people that know what they are doing and have a shell
access. They don't need to belong to a particular site.

*** admin permissions

They can change a subset of site settings (notably, the ones which
don't require restarting the webserver or shell access) in addition to
the librarian permissions (see below). Only a root user can promote an
user to admin. Users they create are always librarians.

*** librarian permissions

Every site can and should have one or more librarians with login. They
are able to access the revisions, approve the texts, etc. Special
pages are always reserved for them.

They can also create fellow librarians which will share the same
privileges. They are peers and they can create peers.

*** human permissions

This is not strictly speaking a role, because no login is required.
Anyway, to access some part of the sites (adding new texts, editing,
the bookbuilder), a prove that the user is a human and not a bot is
required. This is implemented via a question which the human has to
answer. It takes 10 seconds and after that the humanity of the user is
not questioned any more. Also, they should have cookies enabled
(otherwise we can't store a session for them).

*** robot permissions

Humans which don't prove to be such and robots can access all the
public part, including reading and download.

** Modes

Each site can run in one of these three modes, which differ on the
privileges granted to the humans.

*** private

Only logged in can access texts and the site.

*** blog

This mode restricts access to the text editing to librarians only.
Humans can still use the bookbuilder.

*** modwiki

This mode is a "moderated wiki". Humans can add new texts and edit
them, but approvals and publishing is reserved to the librarians.

*** openwiki

This mode is an "open wiki". Humans can add new texts, edit them, and
the result is published right away. Revisions are kept in the git, so
it's always possible to revert to a previous one (but could be
complicated and messy). Use at your own risk, but it could make sense
as a private wiki or in a LAN.

** Email notification

On commit emails are sent to the site.mail address, if any, with the
committer in CC, if he minded to leave one. If site.mail is not set
for the site, the whole mailing is skipped, including the notification
to the committer (as we assume we don't want to spam around).

** Templates and public directory:

 - root/static static files (css, js, images)

Deny the following in the webserver configuration:

 - root/themes theme files (override the templates with the same structure)
 - root/src    template directory.


** Local files (favicon.ico, navlogo.png, pagelogo.png, widebanner.png, local.css, local.js, opengraph.png)

These files may provide an override for cosmetics and features (via
js) without tampering the code. These files should be placed in the
site repository, under the directory site_files.

The navigation logo (navlogo.png) needs (and it's enforced to) an
height of 20px.

If pagelogo.png is present, it will be placed before the latest
entries on the special pages. The assigned ids are
"special-pages-logo" for the container and "special-pages-logo-img"
for the image itself.

If widebanner.png is present, then it's used to place a banner below
the navbar (which is fixed). It should have a width of 1170px for
optimal results.

If opengraph.png is present, it will be used for the opengraph
protocol. The image opengraph.png should have dimension 300x300 for
better effect. If not present, pagelogo.png will be used, otherwise
navlogo.png will be used, with often odd results.

** Local PO files

See LOCALIZATION.txt

** CONFIGURATION FILE

If amusewiki was installed with a package, the location is
/usr/share/perl5/AmuseWikiFarm/amusewikifarm.conf, otherwise is in the
application root.

Further configuration can be done creating a file called
amusewikifarm_local.conf in the same directory of the provided one, if
needed.

If amusewiki was installed with a package, the webserver root is
/usr/share/perl5/AmuseWikiFarm/root/, otherwise is "./root" in the
application directory.

** LET'S ENCRYPT

By default, during the installation a self-signed certificate is
created. This should be good enough to get you started.

You can set the path to the key and certificate in the admin console,
if you already have them.

If you don't have the certificate, you can request a free, valid, and
hassle-free certificate from Let's Encrypt, turning on the option in
the admin console.

Once enabled, the LE certificates will be checked by the amusewiki
daemon once a day, and renewed automatically if needed (a month before
the expiration). The problem is that you still have to reload the
webserver for the new certificates to pick up. If the logger is
sending you mail, you should see the warning.

Anyway, the debian package installs a cronjob in /etc/cron.daily to
reload nginx once a day to avoid the need to login and reload
manually. You should do the same. See debian/amusewiki.cron.daily

Procedure to create a site with SSL certificates using Let's Encrypt:

First, login in the admin and create the site.

Reload the webserver as per instructions.

  # this will print out the instruction to update the webserver conf
  script/amusewiki-generate-nginx-conf

  # update the nginx config as per instructions given by the above command.

  # this will fetch the certificates
  script/amusewiki-letsencrypt

  # Refresh the configuration to actually use the certificates.
  script/amusewiki-generate-nginx-conf 

In the past, a setup with simp_le was suggested. Please remove
existing cronjobs if you used it.

** MAIL WITH SMTP

You need to set the desired parameter as environment variable (in the
systemd unit file or in the user starting the application). See
https://metacpan.org/pod/Email::Sender::Manual::QuickStart and
https://metacpan.org/pod/Email::Sender::Transport::SMTP for details.

Previously we used the application config file, but that's sloppy
because it prevents the jobber to send mails properly.

Example:

  $ export EMAIL_SENDER_TRANSPORT=SMTP
  $ export EMAIL_SENDER_TRANSPORT_host=smtp.example.com
  $ export EMAIL_SENDER_TRANSPORT_port=2525

** EXPOSE THE GIT REPOSITORY WITH GIT-DAEMON

Make the repositories read-only available via git-daemon.

  apt-get install git-daemon-sysvinit

Change /etc/default/git-daemon to read:

  GIT_DAEMON_ENABLE=true

Start the service

  service git-daemon start

Link the repositories in /var/cache/git (as per package documentation).
Note that in debian jessie it was moved to /var/lib/cache).

Something like this should do, assuming the application root is /var/lib/amusewiki

 root@localhost:/var/cache/git# for i in /var/lib/amusewiki/repo/*; \
     do if [ -d "$i/.git" ]; then echo $(basename $i); \
     ln -s $i/.git $(basename $i).git ; fi ; done

And in your application directory, mark the repository for export:

  $ for i in repo/*/.git ; do touch $i/git-daemon-export-ok; done

** PASSWORD RECOVERY

Password recovery is email-based. Now, if the user is without a mail
or the user is not assigned to the site where the request is done
(notably, root users don't need to be assigned to a site), the request
is void.

To avoid disclosing who is a user and who is not on the site, the
reset password page doesn't say if the request was OK or not.

** POPULAR SORTING

This feature is still experimental and there is no linking to it. Link
is /stats/popular.


